{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RiainFall Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math \n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sb \n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data heads:\n",
      "                 SUBDIVISION  YEAR   JAN    FEB   MAR    APR    MAY    JUN  \\\n",
      "0  ANDAMAN & NICOBAR ISLANDS  1901  49.2   87.1  29.2    2.3  528.8  517.5   \n",
      "1  ANDAMAN & NICOBAR ISLANDS  1902   0.0  159.8  12.2    0.0  446.1  537.1   \n",
      "2  ANDAMAN & NICOBAR ISLANDS  1903  12.7  144.0   0.0    1.0  235.1  479.9   \n",
      "3  ANDAMAN & NICOBAR ISLANDS  1904   9.4   14.7   0.0  202.4  304.5  495.1   \n",
      "4  ANDAMAN & NICOBAR ISLANDS  1905   1.3    0.0   3.3   26.9  279.5  628.7   \n",
      "\n",
      "     JUL    AUG    SEP    OCT    NOV    DEC  ANNUAL  Jan-Feb  Mar-May  \\\n",
      "0  365.1  481.1  332.6  388.5  558.2   33.6  3373.2    136.3    560.3   \n",
      "1  228.9  753.7  666.2  197.2  359.0  160.5  3520.7    159.8    458.3   \n",
      "2  728.4  326.7  339.0  181.2  284.4  225.0  2957.4    156.7    236.1   \n",
      "3  502.0  160.1  820.4  222.2  308.7   40.1  3079.6     24.1    506.9   \n",
      "4  368.7  330.5  297.0  260.7   25.4  344.7  2566.7      1.3    309.7   \n",
      "\n",
      "   Jun-Sep  Oct-Dec  \n",
      "0   1696.3    980.3  \n",
      "1   2185.9    716.7  \n",
      "2   1874.0    690.6  \n",
      "3   1977.6    571.0  \n",
      "4   1624.9    630.8  \n",
      "Null values in the dataset before preprocessing:\n",
      "SUBDIVISION     0\n",
      "YEAR            0\n",
      "JAN             4\n",
      "FEB             3\n",
      "MAR             6\n",
      "APR             4\n",
      "MAY             3\n",
      "JUN             5\n",
      "JUL             7\n",
      "AUG             4\n",
      "SEP             6\n",
      "OCT             7\n",
      "NOV            11\n",
      "DEC            10\n",
      "ANNUAL         26\n",
      "Jan-Feb         6\n",
      "Mar-May         9\n",
      "Jun-Sep        10\n",
      "Oct-Dec        13\n",
      "dtype: int64\n",
      "Filling null values with mean of that particular column\n",
      "Mean of data:\n",
      "YEAR       1958.218659\n",
      "JAN          18.957320\n",
      "FEB          21.805325\n",
      "MAR          27.359197\n",
      "APR          43.127432\n",
      "MAY          85.745417\n",
      "JUN         230.234444\n",
      "JUL         347.214334\n",
      "AUG         290.263497\n",
      "SEP         197.361922\n",
      "OCT          95.507009\n",
      "NOV          39.866163\n",
      "DEC          18.870580\n",
      "ANNUAL     1411.008900\n",
      "Jan-Feb      40.747786\n",
      "Mar-May     155.901753\n",
      "Jun-Sep    1064.724769\n",
      "Oct-Dec     154.100487\n",
      "dtype: float64\n",
      "Null values in the dataset after preprocessing:\n",
      "SUBDIVISION    0\n",
      "YEAR           0\n",
      "JAN            0\n",
      "FEB            0\n",
      "MAR            0\n",
      "APR            0\n",
      "MAY            0\n",
      "JUN            0\n",
      "JUL            0\n",
      "AUG            0\n",
      "SEP            0\n",
      "OCT            0\n",
      "NOV            0\n",
      "DEC            0\n",
      "ANNUAL         0\n",
      "Jan-Feb        0\n",
      "Mar-May        0\n",
      "Jun-Sep        0\n",
      "Oct-Dec        0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Shape:  (4116, 19)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"rainfall in india.csv\") \n",
    "print(\"Data heads:\") \n",
    "print(data.head()) \n",
    "print(\"Null values in the dataset before preprocessing:\") \n",
    "print(data.isnull().sum()) \n",
    "print(\"Filling null values with mean of that particular column\") \n",
    "data=data.fillna(np.mean(data)) \n",
    "print(\"Mean of data:\") \n",
    "print(np.mean(data)) \n",
    "print(\"Null values in the dataset after preprocessing:\") \n",
    "print(data.isnull().sum()) \n",
    "print(\"\\n\\nShape: \",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4116 entries, 0 to 4115\n",
      "Data columns (total 19 columns):\n",
      "SUBDIVISION    4116 non-null object\n",
      "YEAR           4116 non-null int64\n",
      "JAN            4116 non-null float64\n",
      "FEB            4116 non-null float64\n",
      "MAR            4116 non-null float64\n",
      "APR            4116 non-null float64\n",
      "MAY            4116 non-null float64\n",
      "JUN            4116 non-null float64\n",
      "JUL            4116 non-null float64\n",
      "AUG            4116 non-null float64\n",
      "SEP            4116 non-null float64\n",
      "OCT            4116 non-null float64\n",
      "NOV            4116 non-null float64\n",
      "DEC            4116 non-null float64\n",
      "ANNUAL         4116 non-null float64\n",
      "Jan-Feb        4116 non-null float64\n",
      "Mar-May        4116 non-null float64\n",
      "Jun-Sep        4116 non-null float64\n",
      "Oct-Dec        4116 non-null float64\n",
      "dtypes: float64(17), int64(1), object(1)\n",
      "memory usage: 611.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Info:\") \n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group by:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Station'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6c9be5da9616>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Group by:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Station'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m   7630\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m   7631\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7632\u001b[1;33m                        observed=observed, **kwargs)\n\u001b[0m\u001b[0;32m   7633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7634\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   2108\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2110\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m                                                     \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m                                                     mutated=self.mutated)\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[0;32m    576\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Station'"
     ]
    }
   ],
   "source": [
    "print(\"Group by:\") \n",
    "data.groupby('Station').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Co-Variance =\",data.cov()) \n",
    "print(\"Co-Relation =\",data.corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cols=data.corr()['ANNUAL'].sort_values()[::-1] \n",
    "print(\"Index of correlation columns:\",corr_cols.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"scatterplot of annual and january attribures\")\n",
    "plt.scatter(data.ANNUAL,data.JAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Box plot of annual rainfall data in year 1901-2015\")\n",
    "data['ANNUAL'].plot(kind='box',sharex=False,sharey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Histograms showing the data from attributes (JANUARY to DECEMBER) of the years 1901-2015:\") \n",
    "data['JAN'].hist(bins=20) \n",
    "data['FEB'].hist(bins=20) \n",
    "data['MAR'].hist(bins=20) \n",
    "data['APR'].hist(bins=20) \n",
    "data['MAY'].hist(bins=20) \n",
    "data['JUN'].hist(bins=20) \n",
    "data['JUL'].hist(bins=20) \n",
    "data['AUG'].hist(bins=20) \n",
    "data['SEP'].hist(bins=20) \n",
    "data['OCT'].hist(bins=20) \n",
    "data['NOV'].hist(bins=20) \n",
    "data['DEC'].hist(bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Histogram showing the annual rainfall of the all states:\") \n",
    "data['ANNUAL'].hist(bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Violin plot of the ANNUAL attribute :-\") \n",
    "sb.violinplot(data=data['ANNUAL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=data.drop(['SUBDIVISION','YEAR','ANNUAL','Jan-Feb','Mar-May','Jun-Sep','Oct-Dec'],axis=1) \n",
    "k=((d2.head().sum())) \n",
    "month=list(d2.head()) \n",
    "print(\"Months are: \",month) \n",
    "print(k) \n",
    "s=0 \n",
    "for i in d2.sum():    \n",
    "    s=s+i \n",
    "print(\"Total recorded rainfall in these 12 months\",s) \n",
    "probability=list(k/s) \n",
    "print(probability) \n",
    "max_rainfall=max(probability) \n",
    "for i in range(len(month)):    \n",
    "    if probability[i]==max_rainfall:        \n",
    "        print(\"Maximum Rainfall will be in the month of\",month[i]) \n",
    "min_rainfall=min(probability) \n",
    "for i in range(len(month)):    \n",
    "    if probability[i]==min_rainfall:        \n",
    "        print(\"Minimum Rainfall will be in the month of\",month[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model \n",
    "print(\"___Multiple Linear regression model between annual rainfall and the periodic rainfall___\") \n",
    "y=data['ANNUAL'] \n",
    "x=data[['Jan-Feb','Mar-May','Jun-Sep','Oct-Dec']] \n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.3,shuffle=False) \n",
    "'''train_x=train_x[:,np.newaxis] test_x=test_x[:,np.newaxis]''' \n",
    "print(\"Train x shape\",train_x.shape,\"; Test_x\",test_x.shape) \n",
    "print(\"Train y shape\",train_y.shape,\"; Test_y\",test_y.shape) \n",
    "lm=linear_model.LinearRegression() \n",
    "lm.fit(train_x,train_y) \n",
    "pred=lm.predict(test_x) #print(test_y) #print(pred) \n",
    "print(\"Mean Squared Error =\",mean_squared_error(test_y,pred)) \n",
    "print(\"Root Mean Squared Error =\",np.sqrt(mean_squared_error(test_y,pred))) \n",
    "print(\"Mean Absolute Error =\",mean_absolute_error(test_y,pred)) \n",
    "print(\"r2_score =\",r2_score(test_y,pred)) \n",
    "plt.scatter(pred,test_y) \n",
    "plt.xlabel('TRAIN_X') \n",
    "plt.ylabel('TRAIN_Y') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected=[] \n",
    "for i in test_y:    \n",
    "    if i>2000:        \n",
    "        expected.append(\"high\")    \n",
    "    else: \n",
    "        expected.append(\"low\") \n",
    "predicted=[] \n",
    "for i in pred:    \n",
    "    if i>2000:        \n",
    "        predicted.append(\"high\")    \n",
    "    else:        \n",
    "        predicted.append(\"low\") \n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report \n",
    "acc=accuracy_score(predicted,expected) \n",
    "matrix=confusion_matrix(predicted,expected) \n",
    "clas=classification_report(predicted,expected) \n",
    "print(\"accuracy\") \n",
    "print(acc) \n",
    "print(\"\\n\") \n",
    "print(\"classification\") \n",
    "print(clas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=[] \n",
    "pre=[] \n",
    "for i in expected:    \n",
    "    if i=='high':        \n",
    "        exp.append(1)    \n",
    "    else:        \n",
    "        exp.append(0) \n",
    "for i in predicted:    \n",
    "    if i=='high':       \n",
    "        pre.append(1)    \n",
    "    else:        \n",
    "        pre.append(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc \n",
    "import random \n",
    "fpr,tpr,threshold=roc_curve(exp,pre) \n",
    "roc_auc=auc(fpr,tpr) \n",
    "plt.title(\"receiver curve operating characteristic\") \n",
    "plt.plot(fpr,tpr,'b',label='AUC = %0.2f'%roc_auc) \n",
    "plt.legend(loc='lower right') \n",
    "plt.plot([0,1],[0,1],'r--') \n",
    "plt.xlim([-0.1,1.2]) \n",
    "plt.ylim([-0.1,1.2]) \n",
    "plt.ylabel(\"True Positive Rate\") \n",
    "plt.xlabel(\"False Positive Rate\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
